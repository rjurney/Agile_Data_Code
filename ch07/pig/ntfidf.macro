/* Derived from TF-IDF by Jacob Perkins at http://thedatachef.blogspot.com/2011/04/tf-idf-with-apache-pig.html with
 help from Mat Kelcey who referred me to http://nlp.stanford.edu/IR-book/html/htmledition/maximum-tf-normalization-1.html */

DEFINE ntf_idf(token_records, id_field, token_field) RETURNS out_relation {
   
  /* Calculate the term count per document */
  doc_word_totals = foreach (group $token_records by ($id_field, $token_field)) generate 
    FLATTEN(group) as ($id_field, token), 
    COUNT_STAR($token_records) as doc_total;
 
  /* Calculate the document size */
  pre_term_counts = foreach (group doc_word_totals by $id_field) generate
    group AS $id_field,
    FLATTEN(doc_word_totals.(token, doc_total)) as (token, doc_total), 
    SUM(doc_word_totals.doc_total) as doc_size,
    MAX(doc_word_totals.doc_total) as max_freq;
 
  /* Calculate the TF */
  term_freqs = foreach pre_term_counts generate 
    $id_field as $id_field,
    token as token,
    ((double)doc_total / (double)doc_size / (double) max_freq) AS term_freq;
  
  /* Get count of documents using each token, for idf */
  token_usages = foreach (group term_freqs by token) generate
    FLATTEN(term_freqs) as ($id_field:chararray, token:chararray, term_freq:double),
    COUNT_STAR(term_freqs) as num_docs_with_token;
 
  /* Get document count */
  just_ids = foreach $token_records generate $id_field;
  just_ids = DISTINCT just_ids;
  ndocs = foreach (group just_ids all) generate COUNT_STAR(just_ids) as total_docs;
 
  /* Note the use of Pig Scalars to calculate idf */
  scores = foreach token_usages {
    idf    = LOG((double)ndocs.total_docs/(double)num_docs_with_token);
    ntf_idf = (double)term_freq * idf;
    generate $id_field as $id_field,
      token as token,
      (double)ntf_idf as score:double;
  };
  
  $out_relation = filter scores by token IS NOT NULL and token != '' and LENGTH(token) > 2; -- score > 0.10 and
};
